---
title: "Structural Topic Analysis"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

rm(list=ls()) #clears variables in global environment 
#dev.off() #clears plots in history

library(dplyr)
library(parallel)
library(SnowballC)
library(stm)
library(stringr)
library(tm)
library(wordcloud)
library("topicmodels")

getwd() #setwd("C:/Users/tgunda/Desktop/WaterPlanProject")
```

Read in data

```{r}
list.files(pattern = "rds", ignore.case=TRUE)
latest_data <- readRDS("FinalDataFrame.Rds")
str(latest_data)

#data quality issues
latest_data %>%
  filter(`Plan(1=YES) ` == 1 & is.na(Plan_Text))

latest_data %>%
StateList <- readRDS("StateList.Rds")

StateList$`Plan Type` <- as.factor(StateList$`Plan Type`)

Droughtplans_raw <- readRDS("DroughtPlansRaw_text.Rds")

Droughtplans_processed <- readRDS("DroughtPlansProcessed_text.Rds")

waterplans_text <- readRDS("WaterPlans_text.rds")

waterplans_rawtext <- readRDS("WaterPlansRaw_text.rds")


```

###Document Term Matrix -- Water Plans

Before we conduct the topic modeling, we first need to construct the DTM

```{r}


WaterPlans_text <- readRDS(file = "~/WaterPlans_text.rds")

WaterPlans.dtm <- DocumentTermMatrix(WaterPlans_text, 
                                     control = list(stopwords = TRUE,
                                                    stemming = TRUE,
                                                    bounds = list(global = c(3, Inf))))

WaterPlans.dtm 

inspect(WaterPlans.dtm[1:10,]) 


#make sure there are no zeros in the dtm
raw.sum <- apply(WaterPlans.dtm,1,FUN=sum) 

raw.sum #no zeros

```




Conducting the Topic Modeling and creating graphics 

```{r}

Topics_Exploration <- function(No_Topics) {
  waterplan_lda <- LDA(WaterPlans.dtm, k = No_Topics, control = list(seed = 1234))
  

  #convert into a tidy object
  waterplan_topics <- tidy(waterplan_lda, matrix = "beta")
  
  plot1 <- drought_topics %>%
    group_by(topic) %>%
    top_n(5, beta) %>%
    ungroup() %>%
    arrange(topic, -beta) %>%
    mutate(term = reorder(term, beta)) %>%
    ggplot(aes(term, beta, fill = factor(topic))) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~ topic, scales = "free") +
    coord_flip()
  print(plot1)
  
  return(drought_lda)  
}



WaterPlanDocs_2LDA <- Topics_Exploration(No_Topics=2)
WaterPlanDocs_2LDA <- Topics_Exploration(No_Topics=3)
WaterPlanDocs_2LDA <- Topics_Exploration(No_Topics=4)
WaterPlanDocs_2LDA <- Topics_Exploration(No_Topics=5)



```


Now do the same thing with the drought plans

```{r}


DroughtPlans_text <- readRDS(file = "~/DoughtPlans_text.rds")

DroughtPlans.dtm <- DocumentTermMatrix(DroughtPlans_text, 
                                     control = list(stopwords = TRUE,
                                                    stemming = TRUE,
                                                    bounds = list(global = c(3, Inf))))

DroughtPlans.dtm 

inspect(DroughtPlans.dtm[1:10,]) 


#make sure there are no zeros in the dtm
raw.sum <- apply(DroughtPlans.dtm,1,FUN=sum) 

raw.sum #no zeros

Topics_Exploration <- function(No_Topics) {
  droughtplan_lda <- LDA(DroughtPlans.dtm, k = No_Topics, control = list(seed = 1234))
  

  #convert into a tidy object
  droughtplan_topics <- tidy(droughtplan_lda, matrix = "beta")
  
  plot1 <- drought_topics %>%
    group_by(topic) %>%
    top_n(5, beta) %>%
    ungroup() %>%
    arrange(topic, -beta) %>%
    mutate(term = reorder(term, beta)) %>%
    ggplot(aes(term, beta, fill = factor(topic))) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~ topic, scales = "free") +
    coord_flip()
  print(plot1)
  
  return(drought_lda)  
}



DroughtPlanDocs_2LDA <- Topics_Exploration(No_Topics=2)
DroughtPlanDocs_2LDA <- Topics_Exploration(No_Topics=3)
DroughtPlanDocs_2LDA <- Topics_Exploration(No_Topics=4)
DroughtPlanDocs_2LDA <- Topics_Exploration(No_Topics=5)





```

Prepare raw data 

```{r}
#which variables do we want to use as control factors? date? state name?
#state as factor
#date as numeric

#Sample code below
#write out metadata
meta_Top3 <- alldata_filt_Top3 %>% select(source, datenum)
str(meta_Top3)
meta_Top3$source <- as.factor(meta_Top3$source)
str(meta_Top3)

#start processing data
set.seed(916916)

system.time(textPro_Top3 <- textProcessor(alldata_filt_Top3$fulltext,
                                          metadata=meta_Top3,
                                          stem=F,
                                          verbose=T)) #7500 s

system.time(textPrep_Top3 <- prepDocuments(textPro_Top3$documents,
                                           textPro_Top3$vocab,
                                           textPro_Top3$meta,
                                           lower.thresh=0,
                                           verbose=T)) #500s

```

Execute searchK to ID right number of topics

```{r}
detectCores() #72
Ks <- 2:50 #broken it up into 2 chunks; one on this guy, one on Matt's comp

system.time(kresult_allart_top3 <- searchK(textPrep_Top3$documents,
                                           textPrep_Top3$vocab,
                                           Ks,
                                           data=textPrep_Top3$meta,
                                           heldout.seed=916916,
                                           cores=6))

# pdf(file="searchK_utga_filt.pdf",width=6.5, height=6.5)
# plot(kresult_utga_filt)
# dev.off()
```

After looking at searchK, execute stm with X # of topics

```{r}
# system.time(All_stm100 <- stm(docs,vocab,K=100,
#                               prevalence = ~source+s(datenum),max.em.its = 100,
#                               data=meta,init.type="Spectral",
#                               seed=916916,
#                               verbose=T,
#                               control=c(maxV=10000),
#                               gamma.prior = "L1")) #1876185s elapsed ~ 21+ days
# 
# save.image(file="Allart_stm4filter.Rdata")

```

Explore topics: can look at words within topics as well as correlations between topics
Could also include a lot of the general plotting approaches from the "Basic Topic Analysis.Rmd" file here too

```{r}
#print out labelTopics
# library(writexl)
# 
# temp <- labelTopics(All_stm100) #spit out quick summary of main words/frex words
# 
# prob = as.data.frame(temp$prob)
# prob$TopicNum <- paste("T",1:100,sep = "")
# frex = as.data.frame(temp$frex)
# frex$TopicNum <- paste("T",1:100,sep = "")
# lift = as.data.frame(temp$lift)
# lift$TopicNum <- paste("T",1:100,sep = "")
# score = as.data.frame(temp$score)
# score$TopicNum <- paste("T",1:100,sep = "")
# sheets <- list("prob" = prob,
#                "frex" = frex,
#                "lift" = lift,
#                "score" = score)
# write_xlsx(sheets,"Allart/labeltopics_allart_filter.xlsx")
# rm(prob,frex,lift,score,sheets)
# 
# #topic correlations & networks
# all_corr <- topicCorr(model=All_stm100,
#                        method = "simple",
#                        cutoff = 0.01)
# write.table(all_corr$cor,"Allart/all_corr.txt",sep=",")

# utga_corr <- read.csv("utga_corr.csv") #only has the corr matrix
# utga_corr_abs <- abs(utga_corr) #do abs value of cor
# utga_corr_abs <- as.matrix(utga_corr_abs)
# summary(utga_corr_abs)
# str(utga_corr_abs)
# 
# p_network_topics_utga <- graph_from_adjacency_matrix(utga_corr_abs,mode="undirected",weighted=TRUE,diag=FALSE)
# plot.new()
# plot(p_network_topics_utga, edge.width=E(p_network_topics_utga)$weight*6)
# 
# #dendograms of topics - also for filtering
# comm_walktrap_utga <- cluster_walktrap(p_network_topics_utga) #weights are set as default
# membership(comm_walktrap_utga)
# plot_comm_walktrap_az <- set_vertex_attr(p_network_topics_az_orig,"mem_az",value = membership(comm_walktrap_az))
# plot(as.dendrogram(comm_walktrap_utga))
# 
# #topic proportions
# theta_mean <- colMeans(BothStates_stm100$theta)
# write.csv(theta_mean,"thetamean_utga.csv")
# summary(theta_mean)


```

