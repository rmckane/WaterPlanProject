---
title: "Water and Drought Plans"
author: "Rachel McKane"
date: "August 28, 2017"
output: html_document
---

```{r setup, include=FALSE}
rm(list=ls()) #clears variables in global environment 
#dev.off() #clears plots in history

knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(root.dir = "  ") # Set your root directory 


library("tidyverse") #includes dplyr, ggplot2, tidyr, purr, readr, and tibble
# library("broom") #has the tidy fn to convert non-tidy objects into tidy objects
# library("SnowballC")
# library("stringr") #has str_extract fn to avoid some of the strange utf-8 text encodings
# library("tm") #has a lot of text cleaning fns, like remove numbers and punctuation; incl. NLP and slam
# library("tidytext") #has unnest_tokens fn; includes SnowballC; #has tidy fn to convert topics into tidy format
# library("wordcloud")
# library("quanteda") #searching for specific words
# library("pdftools") #reading in pdfs

getwd()#setwd("C:/Users/tgunda/Desktop/WaterPlanProject")
```

Read in data

```{r}
list.files(pattern = "rds", ignore.case=TRUE)
latest_data <- readRDS("FinalDataFrame.Rds")
str(latest_data)

#data quality issues
latest_data %>%
  filter(`Plan(1=YES) ` == 0) %>%
  count() #60

sum(is.na(latest_data$Plan_Text)) #61 NAs, one more NA than 0 plan

latest_data %>%
  filter(`Plan(1=YES) ` == 1 & is.na(Plan_Text)) #PA WaterPlanProcessed has no text

latest_data %>%
  filter(StateAbbreviation =="PA" & PlanType =="WaterPlanRaw") %>%
  select(Plan_Text)
```


###Read in the RDS file with the Corpus of Water Plans

For this analysis we are working with the water plans in text format to search specific words. 
Start by reading in the RDS file that contains all of the clean text files.  

```{r}

WaterPlans_text <- readRDS(file = "~/WaterPlans_text.rds")

```


###Total Terms with Stopwords for Water Plans

It is easier to use the quanteda package for word searching, so we start by converting our VCorpus (from the tm package) to a quanteda corpus. 

```{r}

WaterPlanCorpus <- corpus(WaterPlans_text)
total_terms_raw <- summary(WaterPlanCorpus)
total_terms_raw_words <- total_terms_raw$Tokens


```

### Word Searches for Water Plans

Now we can search for specific words. 

```{r}

#Sustainability
sust<- kwic(WaterPlanCorpus, "sustainability") 
sust<- table(sust$docname) %>% tidy()
sust<- sust %>% dplyr::rename(State = "Var1", Sustainability = "Freq")


#Climate Change
cc<- kwic(WaterPlanCorpus, c(phrase("climate change")))
cc<- table(cc$docname) %>% tidy()
cc<- cc %>% dplyr::rename(State = "Var1", Climate_Change = "Freq")

#Scarcity 
scar<- kwic(WaterPlanCorpus, "scarcity") 
scar<- table(scar$docname) %>% tidy()
scar<- scar %>% dplyr::rename(State = "Var1", Scarcity = "Freq")


#Climate Varaibility 
cv<- kwic(WaterPlanCorpus, c(phrase("climate variability")))
cv<- table(cv$docname) %>% tidy()
cv<- cv %>% dplyr::rename(State = "Var1", Climate_Variability = "Freq")


#Extreme Events
ee<- kwic(WaterPlanCorpus, c(phrase("extreme events")))
ee<- table(ee$docname) %>% tidy()
ee<- ee %>% dplyr::rename(State = "Var1", Extreme_Events = "Freq")

#Quality
qq<- kwic(WaterPlanCorpus, c(phrase("quality")))
qq<- table(qq$docname) %>% tidy()
qq<- qq %>% dplyr::rename(State = "Var1", Quality = "Freq")


```

### Cleaning up Word Data for Water Plans 

Now we can clean up our word data, standardize our findings by the total number of words in each doument, and create a table that has all of our results. 

```{r}

word_data_waterplans <- total_terms %>% left_join(cc) %>% left_join(sust) %>% 
  left_join(scar) %>% left_join(cv) %>% left_join(ee) %>% left_join(qq)

word_data_waterplans <- word_data_waterplans %>%
  mutate(Climate_Change_Percent = Climate_Change/Total_Words*100,
         Sustainability_Percent = Sustainability/Total_Words*100,
         Climate_Variabiliyt_Percent = Climate_Variability/Total_Words*100,
         Extreme_Events_Percent = Extreme_Events/Total_Words*100,
         Quality_Percent = Quality/Total_Words*100)

write.csv(word_data_waterplans,"~/word_data_waterplans.csv")

```


Now, we can do the same thing with the drought plans...


```{r}

DroughtPlans_text <- readRDS(file = "~/DroughtPlans_text.rds")


DroughtPlanCorpus <- corpus(DroughtPlans_text)
total_terms_raw <- summary(DroughtPlanCorpus)
total_terms_raw_words <- total_terms_raw$Tokens

#Sustainability
sust<- kwic(DroughtPlanCorpus, "sustainability") 
sust<- table(sust$docname) %>% tidy()
sust<- sust %>% dplyr::rename(State = "Var1", Sustainability = "Freq")


#Climate Change
cc<- kwic(DroughtPlanCorpus, c(phrase("climate change")))
cc<- table(cc$docname) %>% tidy()
cc<- cc %>% dplyr::rename(State = "Var1", Climate_Change = "Freq")

#Scarcity 
scar<- kwic(DroughtPlanCorpus, "scarcity") 
scar<- table(scar$docname) %>% tidy()
scar<- scar %>% dplyr::rename(State = "Var1", Scarcity = "Freq")


#Climate Varaibility 
cv<- kwic(DroughtPlanCorpus, c(phrase("climate variability")))
cv<- table(cv$docname) %>% tidy()
cv<- cv %>% dplyr::rename(State = "Var1", Climate_Variability = "Freq")


#Extreme Events
ee<- kwic(DroughtPlanCorpus, c(phrase("extreme events")))
ee<- table(ee$docname) %>% tidy()
ee<- ee %>% dplyr::rename(State = "Var1", Extreme_Events = "Freq")

#Quality
qq<- kwic(DroughtPlanCorpus, c(phrase("quality")))
qq<- table(qq$docname) %>% tidy()
qq<- qq %>% dplyr::rename(State = "Var1", Quality = "Freq")


word_data_droughtpans <- total_terms %>% left_join(cc) %>% left_join(sust) %>% 
  left_join(scar) %>% left_join(cv) %>% left_join(ee) %>% left_join(qq)

word_data_droughtpans  <- word_data_droughtpans  %>%
  mutate(Climate_Change_Percent = Climate_Change/Total_Words*100,
         Sustainability_Percent = Sustainability/Total_Words*100,
         Climate_Variabiliyt_Percent = Climate_Variability/Total_Words*100,
         Extreme_Events_Percent = Extreme_Events/Total_Words*100,
         Quality_Percent = Quality/Total_Words*100)

write.csv(word_data_drouggtplans,"~/word_data_droughtplans.csv")


```
